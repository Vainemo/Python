监督学习：
   如果样本带有预先设定的的标签，就说我们正在进行监督学习
   监督学习有两种类型：1.分类 2.回归
   分类：分类是指遍历一个给定的类别集合，之后找到最适合描述特定输入的类别
   回归：回归是指通过一组测量值来预测一些其他的值（通常是下一个值，但也可能是在集合开始之前或中间的某个地方的数值）
无监督学习：
   当输入数据没有标签时，从这些数据中学习的算法均称为无监督学习
   无监督学习通常用于解决我们称之为“聚类”“降噪”和“降维”的问题
   聚类：将一组数据按照相似性分为不同的类
   降噪：去掉样本中的不确定性或其他失真。
   降维：去掉一些不需要关注的特征，减少我们描述数据所需要的值（或维度）
生成器：
    生成器是处于中间地带的，它不需要标签，但是又从我们这里得到了一些反馈，因此我们把这一中间地带称为半监督学习
强化学习：
   强化学习不同于监督学习，因为数据没有标签，虽然从错误中学习这一总体思路是相同的，但是作用的机制不同
   相比之下，在监督学习中，由系统生成一个结果（通常是一个类别或一个预测值），然后我们将其与所提供的正确
   结果进行比较；而在强化学习中，是没有正确结果的，因为数据没有标签，而是通过反馈来告诉我们做得有多好
   特点：环境（道路反馈）会向智能体（自动驾驶的汽车）发送一个奖励信号，这个奖励信号是一个程度值
深度学习：
   基于一系列的离散的层（layer）构建机器学习算法。如果将这些层垂直堆叠，就说这个结果是有深度
  （depth）的，或者说算法是有深度的。
  泛化误差：如果预测大部分是正确的，那么我们就说它具有很高的准确率，或者说泛化误差（generalization error）很小。
贝叶斯
   似然：P(D∣θ)事件θ发生的情况下D发生的概率
   先验：P(θ) 是先验分布，表示在观测数据之前对参数θ的不确定性的概率分布（在抛硬币之前拿到不公平硬币的概率）。
   后验：P(θ∣D)表示在给定数据 D后参数 θ 的条件概率分布（抛一次硬币之后正面朝上，此时手中时公平或不公平硬币的概率分布）
   证据：P(D) 指事件D以任何方式发生的概率(可能挑选的每个硬币正面朝上的概率的和)
数据验证：
    1.想要知道一个系统在新的、未知的数据上能做得多好，首选的方法就是给它新的、未知的数据，
      我们称这些新的数据点或样本为测试数据（test data）或测试集
    2.训练或测试规则：1.我们决不从测试数据中学习，因为会破坏我们对系统总体能力进行评估的可靠性
    3.系统用测试数据进行学习，被称之为数据泄露（data leakage），也称为数据污染（data contamination）或处理受污染数据
    3.通常将原始输入数据拆分为训练集(用来训练系统，学习特征)，验证集（验证系统性能，选择效果最好的超参数，用作学习过程的一部分），测试集（验证系统性能）
    一般流程：
      对于超参数的每一次变化，我们都会训练训练集，而后在验证集上评估系统的性能，之后会选择一组实现效
      果最好的超参数，并通过在从未见过的测试集上运行系统来评估系统的性能。
使用验证数据的结果作为系统的最终评估结果的问题：
      导致数据泄露，因为尽管分类器没有直接地从验证数据中学习，但是验证数据影响了我们对分类器的选择。我们选择了一个在验证数据
      上表现最好的分类器，在正式应用前，我们对分类器在验证数据上的表现的了解将“泄露”到最终的评估情况中
交叉验证：（当数据量过少时）
      每次训练时将训练数据分割为临时训练集和临时验证集时，这些数据被分割为新的集，这样每次的数据都是全新的，未知的，
      所以用它来评估分类器的性能是公平的。
K折叠交叉验证：
      将训练数据拆分为1-5块，通过索引循环，每次拿1块当验证集，其余4块作为训练集，这样我们就可以将所有数据都拿来训练
      
     