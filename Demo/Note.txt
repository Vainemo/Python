监督学习：
   如果样本带有预先设定的的标签，就说我们正在进行监督学习
   监督学习有两种类型：1.分类 2.回归
   分类：分类是指遍历一个给定的类别集合，之后找到最适合描述特定输入的类别
   回归：回归是指通过一组测量值来预测一些其他的值（通常是下一个值，但也可能是在集合开始之前或中间的某个地方的数值）

无监督学习：
   当输入数据没有标签时，从这些数据中学习的算法均称为无监督学习
   无监督学习通常用于解决我们称之为“聚类”“降噪”和“降维”的问题
   聚类：将一组数据按照相似性分为不同的类
   降噪：去掉样本中的不确定性或其他失真。
   降维：去掉一些不需要关注的特征，减少我们描述数据所需要的值（或维度）

生成器：
    生成器是处于中间地带的，它不需要标签，但是又从我们这里得到了一些反馈，因此我们把这一中间地带称为半监督学习

强化学习：
   强化学习不同于监督学习，因为数据没有标签，虽然从错误中学习这一总体思路是相同的，但是作用的机制不同
   相比之下，在监督学习中，由系统生成一个结果（通常是一个类别或一个预测值），然后我们将其与所提供的正确
   结果进行比较；而在强化学习中，是没有正确结果的，因为数据没有标签，而是通过反馈来告诉我们做得有多好
   特点：环境（道路反馈）会向智能体（自动驾驶的汽车）发送一个奖励信号，这个奖励信号是一个程度值

深度学习：
   基于一系列的离散的层（layer）构建机器学习算法。如果将这些层垂直堆叠，就说这个结果是有深度
  （depth）的，或者说算法是有深度的。
  泛化误差：系统被部署时，其预测新数据标签如果大部分是正确的，那么我们就说它具有很高的准确率，或者说泛化误差（generalization error）很小。
  训练误差：训练样本时网络状态的某种总体平均值。
  测试误差：测试集中的误差。
  验证误差：验证集中的误差

贝叶斯
   似然：P(D∣θ)事件θ发生的情况下D发生的概率
   先验：P(θ) 是先验分布，表示在观测数据之前对参数θ的不确定性的概率分布（在抛硬币之前拿到不公平硬币的概率）。
   后验：P(θ∣D)表示在给定数据 D后参数 θ 的条件概率分布（抛一次硬币之后正面朝上，此时手中时公平或不公平硬币的概率分布）
   证据：P(D) 指事件D以任何方式发生的概率(可能挑选的每个硬币正面朝上的概率的和)

数据验证：
    1.想要知道一个系统在新的、未知的数据上能做得多好，首选的方法就是给它新的、未知的数据，
      我们称这些新的数据点或样本为测试数据（test data）或测试集
    2.训练或测试规则：1.我们决不从测试数据中学习，因为会破坏我们对系统总体能力进行评估的可靠性
    3.系统用测试数据进行学习，被称之为数据泄露（data leakage），也称为数据污染（data contamination）或处理受污染数据
    3.通常将原始输入数据拆分为训练集(用来训练系统，学习特征)，验证集（验证系统性能，选择效果最好的超参数，用作学习过程的一部分），测试集（验证系统性能）

一般流程：
      对于超参数的每一次变化，我们都会训练训练集，而后在验证集上评估系统的性能，之后会选择一组实现效
      果最好的超参数，并通过在从未见过的测试集上运行系统来评估系统的性能。

使用验证数据的结果作为系统的最终评估结果的问题：
      会导致数据泄露，因为尽管分类器没有直接地从验证数据中学习，但是验证数据影响了我们对分类器的选择。我们选择了一个在验证数据
      上表现最好的分类器，在正式应用前，我们对分类器在验证数据上的表现的了解将“泄露”到最终的评估情况中

交叉验证：（当数据量过少时）
      每次训练时将训练数据分割为临时训练集和临时验证集时，这些数据被分割为新的集，这样每次的数据都是全新的，未知的，
      所以用它来评估分类器的性能是公平的。

K折叠交叉验证：
      将训练数据拆分为1-5块，通过索引循环，每次拿1块当验证集，其余4块作为训练集，这样我们就可以将所有数据都拿来训练

过拟合：
      如果系统在训练数据中学习得很多且表现很好，但在面对新数据时表现得很糟糕，我们就可以说系统是过拟合的

过拟合的原因：
       我们“过多地学习了”或者说“过多地适应了”输入的数据。换句话说，我们从它们中学习得太多了，对一些细节权重过大，导致细节代替了普
      遍规则。

过拟合的解决办法：
       1.通过正则化的方法，我们可以鼓励系统尽可能长时间地学习普遍的规则，而不是去拼命地记住细节
       2.我们可以在捕捉到系统开始记忆这些细节的时候，停止它的学习过程。

欠拟合：
       描述了一种规则太过模糊或者普遍的情况，导致泛化误差过高。

正则化方法：
       1.把各个特征的权重压缩至比较小的数值，使其不会出现某些特征权重过大而成为一般规则，λ（lambda）来表示正则
      化量，越大说明正则化程度越高。

偏差：
       1.在一组数据中，各个数据表现简单相似，没有足够的灵活度，这样的一组数据就表现出了高偏差。

方差：
        2.在一组数据中，各个数据表现复杂切不相同，则它们有着高方差。

感知机：
      有若干个输入值，每个输入值对应一个权重和，权重可自行变化，将输入值✖权重之和加上偏置值作为检测值，经过检测之后输出特定的值

激活函数：
      在感知机的输出处，用一个数学函数替代了整个检测再输出的步骤——它将和值（包括偏置）作为输入，然后返回一个新的值作为输出
      这个函数被称之为激活函数.
偏置：
     偏置是加在加权输入之和结果上的单个数字
偏置技巧：
     将偏置重新标记为输入，将它作为一项输入项
     
-----------------------------------scikit-learn--------------------------------------------------------------------
fit():
      每个估算器都会提供的。它需要两个强制参数，包含估算器将从中学习的样本以及与它们相关联的值（或目标）。

predict()：
      评估函数，一旦训练了估算器，我们就可以要求它用predict()来评估新的样本。这至少需要一个参数，那就是新的样本，我们希望估算器为其赋
      值。例程会返回描述新数据的信息，通常这是一个NumPy数组，每个样本对应一个数字或一个类

decision_function()：
      同样是评估函数，与predict不同，decision_function将一组样本作为输入，并为每个类和每个输入返回“confidence”分数，其中较大的值表示更高的可信度

predict_proba()：
      输出概率，所有分类结果概率和为1，比decision_function()更加直观。

RidgeClassifier：
      分类器，使用Ridge回归算法的分类器版本

RidgeClassifierCV：
      内置交叉方差的RidgeClassifier

集成器：
     估算器的集合称为集成器，使用AdaBoostClassifier()创建集成器，AdaBoostClassifier(RidgeClassifier(), \algorithm=′SAMME′)包含一个分类器和算法参数

变换器（transform）：
      scikit-learn提供了各种各样的对象，称为变换器，它可以执行许多不同类型的数据变换。每个变换器接收一个包含样本数据的NumPy数组，并返回一个变换数组。

pipeline：
      它允许将多个数据处理步骤组合成一个整体，使得数据从原始状态经过一系列的转换和处理后，最终输入到模型中进行训练或预测(预处理对象和分类对象)。

PolynomialFeatures：
      用于进行多项式特征生成的工具。它可以将原始特征集扩展为包含原始特征的各种幂和交互项的集合，从而使模型能够更好地拟合非线性关系，
      参数degree表示多项式的最高阶数，可包含<=degree的所有次幂的特征
---------------------------------------------------------------------------------------------------------
      
-------------------------------------------前馈网络------------------------------------------------------
前馈网络特征：
       使信息仅朝一个方向流动，数据一旦离开节点，就不会返回，最常见的网络结构是排列神经元

DAG(有向无环图):
      神经网络中的一个普遍规则是没有循环（loop）。这意味着来自节点的数据永远不会回到同一个节点，无论它遵循的路径多么迂回

全连接网络:
      全连接网络，其中每个神经元输入来自上一层的所有神经元。

网络崩溃：
       单个神经元所产生的值与复杂网络中的输出值相同。而且结果出现得会更快，占用的计算机内存也更少。那么神经网络永远不会比单个神经元所产生的结果好
       出现这种现象就被称之为网络崩溃。可以使用激活函数(非线性函数：除了加法和乘法以外的函数)来阻止网络崩溃。

非线性环节：
       因为激活函数通常是人工神经元处理过程中唯一的非线性部分，所以激活函数通常被称为非线性环节。

阶跃函数：
       它保持为一个值，直到某个阈值后，会跳转为另一个值；

Heaviside阶跃（Heaviside step）函数：
       阈值是0的阶跃函数

饱和：
       当输入值大于某一个值时，函数将返回相同的值，这种现象被称为饱和;

ReLU(分段线性函数)：
       如果一个函数是由几个部分组成的，而每个部分都是一条直线，那么我们称它是分段线性（piecewise linear）的，它称为修正线性单元
       （rectifiedlinear unit），或者说线性整流函数，使用参数ReLU时，最重要的是永远不要选择1.0的比例因子，因为这样我们就失去了弯折（kink），
       整个函数就是一条直线。

参数ReLU:
       可用于选择缩放的比例.

移位ReLU:
       将函数弯折处向某个方向移动

maxout激活函数：
      结合基本的ReLU和泄漏型ReLU（或参数ReLU），maxout允许我们定义一组直线，每个点的函数的输出是所有直线在那一点求值后最大的  

----------光滑曲线------------
softplus函数：
      将ReLU做了简单的平滑处理

指数式ReLU：
      也被称为ELU，将移位ReLU进行平滑处理。

sigmoid函数：
       1.也称为logistic函数（logistic function）或logistic曲线（logistic curve），“sigmoid函数”这个名字来源于函数曲线与S形的相似   
       2.S形的sigmoid函数也称为逻辑函数或逻辑曲线。对于极负的输入，它的输出值为0；而对于极正的输入，它的输出值为1。
双曲正切（hyperbolic tangent）函数(tanh函数)
       也是S型的，与的sigmoid的区别在于双曲正切函数为非常负的输入值返回−1的输出，而它的过渡区域也会稍微狭窄一点
swish函数：
       基本的ReLU与sigmoid函数的组合，从本质上说，它就是一个ReLU，但是在0的左边出现了一个小而平滑的凹陷，之后函数变平了
光滑曲线缺点：
       它们只能在有限的输入范围内产生有用的结果，在训练神经网络时，导数的值是至关重要的信息，如果导数趋于0，训练就趋于停止
--------------------------------------
softmax函数(归一化指数函数):
       可以把输出项的得分变成概率，所以它被广泛应用于分类器神经网络的末端
------------------------------------------------------------------------------------------------------------------



--------------------------------------------------反向传播---------------------------------------------------------
          神经网络从误差中学习。每次系统进行不正确的预测时，我们都会使用一种称为反向传播的算法来改善其权重

输入层:
      只是输入X和Y的概念分组。这些与神经元不对应，因为这些只是用于存储已提供给网络的样本中特征的内存块.

隐藏层:
      是指神经元A和B所在的第一层，之所以叫作这个名字，是因为神经元A和B在网络“内部”,这对外部的观察者来说是“隐藏”的，他们只能看到输入和输出。

输出层:
      是指提供输出的一组神经元。
-----------------------------------------dalta-------------------------------------
示例：两层神经元，A神经元为第一层，C，D神经元为第二层，AC为A输出到C的权重，Ad为A的Dalta值，Cd为C的Dalta值，AD为A输出到D的权重
      
   A----->C
   A----->D

计算单个神经元Delta的值：
      1.通过对误差函数求导，来判断当A神经元的输出变大或变小时，其误差变化的趋势（越来越小或越来越大）
      2.按书中案例所示,对其导数再次求导，获得当输出值变化时，误差会增加或减少多少（这个系数就是Delta值）
      例：如果将P1（A的最终输出值）增加0.02，那么我们预测误差将改变(−4)×0.02=−0.08。如果将P 1 移到左边，那么它从−1变为−1.1，我们预测误差变化 (−0.1)×(−4)=0.4，
      因此误差会增加0.4。
      3.如果使用了二次代价函数，任何输出神经元的delta只是标签中的值减去该神经元的输出。
      

通过Delta值来更新权重：
      如果想要将误差增加1，就应该在权重上增加1/(Ao×Cd)
      如果将权重增加0.5，即加上0.5×(Ao×Cd )。
      Ao：神经元A计算的原始值，没用乘以权重之前。
     

Ad = (AC×Cd )+(AD×Dd)：通过当前层的神经元的权重与Delta值来计算上一层的Delta值
   Ad：神经元A的Delta.
   AC: 神经元A输出到神经元C的权重.
   Cd：神经元C的Delta。
   AD：神经元A输出到神经元D的权重。
   Dd:神经元D的Delta。
添加激活函数后Dalta值的计算：
  Ad=(AC×Cd )+(AD×Dd)×激活函数的导数在z的Y值
  Z：前一层神经元的最终输入值

学习率：
   在实践中，我们使用称为学习率的超参数来控制每次更新期间权重的变化量，通常用小写的希腊字母η（eta）表示。这是一个介于0
   和1之间的数字，它告诉权重在更新时使用的新计算值的多少来进行更新。即η×(Ao×Cd)×a。
----------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------

-------------------------------------------------------优化器--------------------------------------------------
                                         使用反向传播梯度来改善网络中权重值
衰减参数：
       使用开始大而逐渐变小的梯度的一种简单方法是在每次更新步骤之后将学习率乘以几乎为1的数字，如0.99，我们在每一步上乘以的值η称为衰减参数（decay parameter）。
衰减规划：
       我们可能不希望在每次更新后应用衰减。我们选择随时间改变学习率的特殊方式称为衰减规划。衰减规划通常用epoch表达
       epoch：表示训练集中所有样本数据被正向传播和反向传播一次的过程
批梯度下降：
       在每个epoch后更新一次权重。
随机梯度下降（SGD）：
       在每个样本后更新权重。我们称SGD为在线算法（online algorithm），因为它不需要存储样本，甚至不需要从一个epoch到下一个epoch。它只是处理每个样
       本，并立即更新网络。
mini-batch梯度下降：
      在这里，我们在评估了一些固定数量的样本后更新权重。此数字几乎总是远小于批大小（即训练集中的样本数）。我们将这个较小的数字称为mini-batch大小，
      从训练集中抽取的一组样本是一个mini-batch。
动量梯度下降:
     对于常规的梯度下降，我们就会因为梯度为0而停在平台上，如图19.34a所示。但是如果我们包含一些动量，那么球会持续滚动一段时间。它会减速，但如果我们
     很幸运，它会滚动到足以找到下一个山谷的地方,对于每个步骤，一旦计算出我们希望每个权重变化多少，就会添加少量来自之前步骤的变化。因此，如果给定步骤
     的变化为0或接近0，但我们在上一步有一些较大的变化，则将依靠先前的一些动能，推动我们走过平台
动量放缩因子：
     我们将动量m乘以通常用小写希腊字母γ（gamma）表示的比例因子。有时这被称为动量放缩因子，这是从0到1的值。将m乘以该值可以得到一个新的箭头γm，它指向
     与m相同的方向，但长度相同或更短。然后我们像之前那样在B处找到缩放的梯度ηg。为了找到C点，我们将缩放的动量γm和缩放的梯度ηg加到B点上
Nesterov动量：
     不是在我们当前所在位置使用梯度，而是在将要到达的位置使用梯度
Adagrad：
       自适应梯度学习该算法能够适应（或改变）每个权重的梯度规模。对于每个权重，Adagrad采用我们在更新步骤中使用的梯度，将其求平方（即将其与自身相
       乘），并将其添加到移动总和中。然后将梯度除以从该和得到的值，得到随后用于更新的值。
Adadelta： 
      每次更新权重时，我们将新梯度添加到列表的近端，并将最旧的梯度从远端删除。为了找到我们用来除新梯度的值，我们会将列表中的所有值相加，但还要先将它
      们全部乘以一个基于它们在列表中的位置的数字。最新的值乘以一个较大的值，而最旧的值乘以一个非常小的值。这样，我们的运行总和最大程度上取决于最近的梯度，
      而它受较旧梯度的影响较小.
   参数γ：
      随着时间的推移历史列表缩小的程度。较大的γ值将比较小的γ值更容易“记住”更远的值，并让它们对总和做出贡献。较小的γ值仅关注最近的梯度。
      通常我们将此γ设置为0.9左右。
   参数ε：
      这是一个用于保持计算在数值上稳定的细节。大多数库都会将其设置为一个默认值，由程序员精心选择，以使工作尽可能地有效。因此除非有特定需要，
      否则不应更改它。
RMSprop:
      名称是因为它使用“均方根”运算（通常缩写为“RMS”）来确定向梯度添加（或传播，因此名称中有“prop”）的调整。
Adam：
      自适应矩估计，在Adagrad的基础上添加另一个列表，其中的梯度不进行平方。然后我们可以使用这两个列表来推导出缩放因子。
    参数β1：
       控制了一阶矩（平均梯度）的指数衰减率。较小的β1会使动量估计变化较慢，从而提高稳定性
    参数β2：
       控制了梯度平方的指数衰减速度。与β1类似，较小的β2会使平方梯度估计变化较慢。
      建议将β 1 设置为0.9，将β 2 设置为0.999
------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------深度学习------------------------------------------------------------
深度网络：
      通过一堆层构建的神经网络通常称为深度网络。
张量：
      深度学习网络的机制本质上是对数字的操作，因此一个重要的数据组织概念是数字列表，它可以右不同的维度和长度，为了简化讨论，我们将一个
      具有任意尺寸和维数的列表称为张量
全连接层：
      全连接层也称为FC或密集层（dense layer），是一组从前一层所有神经元那里接收输入的神经元的集合。全连接层在深度学习中被广泛使用。
      有些名为全连接网络（fully-connectedetwork）或多层感知机（Multi-Layer Perceptron，MLP）的网络，就是只由一些全连接层堆叠而成的。
激活函数层：
      我们可以选择在没有激活函数的情况下创建神经元，然后在它们之后放置一个激活函数“层”。这些神经元自身不会有激活函数，但之后随着它们的
      输出传递到该激活层时，激活函数就被应用了。         
dropout层：
      正则化方法之一，延缓过拟合，dropout层不包含任何神经元，不做任何计算。相反，它仅仅是使前一层的部分神经元断开连接。这种层仅仅在训练时有效，当我们使
      用网络来预测时，dropout层是没有影响的。dropout层用一个参数来描述应该受影响的神经元的百分比。在每一轮训练开始前，我们随机选择前一层
      该百分比数量的神经元，之后暂时地切断它们同其他神经元的输入与输出，引入dropout层的目的是防止任何一个神经元过度专门化。
批归一化层：
      正则化方法之二，像dropout一样，批归一化可以作为网络中包含的一层来实现，但这一层也不包含神经元。与dropout不同的是，批归一化实际上做了
      一些计算，尽管没有参数，也不需要我们控制。批归一化用于修改从一个计算层产生的值，比如一个全连接层，对一层的输出值进行一些修改可以使那些
      数字更适合于即将到来的计算，比如缩放变化，不影响相对的输出，所有值都被2除，这改变了它们的绝对大小，但不改变它们的相对大小。因此一个比其他
      值大3倍的值仍然大3倍。
   放缩的意义：
      它是为了保持这些在网络中流动的值不变得过大，保持这些值较小有助于推迟过拟合。
卷积层：
      在二维图像上考虑卷积。除了这个输入图像之外，我们还会创建第二个微小的图像，可能小到3像素×3像素。我们称这个小图为过滤器（filter），把这个小的
      方形过滤器移到整个输入图像上。对于输入的每个像素，我们将把3像素×3像素的图像放在它的中心，然后将3像素×3像素过滤器中每个像素的值与其下方输入图
      像对应像素的值相乘。我们将把那些和值加起来，然后就变成了输出图像中那个像素的值，如果我们有两个过滤器，那么会产生两个输出图像。
池化层：
      池化层（pooling layer）让我们能改变在网络中传递的数据的尺寸。当我们想减小图像的尺寸以便能更快地处理它时通常使用这个过程。对一个二维图像进行池化
      操作时，我们收集小块（通常是正方形），然后用它们数据的某个版本（通常要么是均值，要么是最大值）作为一个全新的、更小的图像的值。
      池化层常用在卷积层之后，用来制作尺寸越来越小的输入图像。但这种方法正逐渐“失宠”，因为卷积层也可以减小图像尺寸。
循环层：
     我们可以用一个更复杂的称为循环单元（recurrent unit）（或循环单位）的处理环节来代替基本的人工神经元以解决缺乏记忆力的问题。我们可以用标准层的
     混搭来搭建深度学习网络，并且层都由循环单元构成。如果循环单元是网络的重要组成部分，我们常常称这个网络为循环神经网络或RNN
                                    
归一化层：
     通过修改流经它的数据来调整网络，或者保持权重值较小以便我们推迟过拟合。批归一化层是归一化层的一个样例。
噪声层：
     给流经它的每条数据增添了随机值。这可以帮助解决免疫其他方法的过拟合，因为它可以阻止神经元对同样的输入数据过于熟练地总产生同样的响应。
重塑层：
     让我们能改变流经它的张量的尺寸。例如，我们可能有一个尺寸为10×3×5的三维输入张量，共计150个元素。我们可能想合并最后两个维度来形成一个二维网格，
     以便将其作为一个图像来处理。我们可以用一个重塑层来宣布它现在应该被理解为一个尺寸为10×15的张量。应记住的是，“重塑”整个概念指导了每一层如何解释
     输入数据。不同尺寸的张量中元素被处理的初级细节在每一层是自动处理的。
剪裁层：
     在处理图像时特别有用。它只是简单地从图像中提取一个矩形区域，然后把其余部分去掉
零填充层：
     常用于卷积和二维图像。它在图像外部放置了一个0值环——该环可以像我们所愿的一样厚。在三维情况下，它在起始的长方体周围放置0值环。
上采样层：
     很像池化层，但它是反向工作的。它会使输入张量更大，而非更小。这通常是通过简单地重复元素完成的。
平整层:
    是重塑层的一种特殊形式，它将任意维数的输入张量转变成一个大的一维列表。
     
