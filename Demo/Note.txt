监督学习：
   如果样本带有预先设定的的标签，就说我们正在进行监督学习
   监督学习有两种类型：1.分类 2.回归
   分类：分类是指遍历一个给定的类别集合，之后找到最适合描述特定输入的类别
   回归：回归是指通过一组测量值来预测一些其他的值（通常是下一个值，但也可能是在集合开始之前或中间的某个地方的数值）
无监督学习：
   当输入数据没有标签时，从这些数据中学习的算法均称为无监督学习
   无监督学习通常用于解决我们称之为“聚类”“降噪”和“降维”的问题
   聚类：将一组数据按照相似性分为不同的类
   降噪：去掉样本中的不确定性或其他失真。
   降维：去掉一些不需要关注的特征，减少我们描述数据所需要的值（或维度）
生成器：
    生成器是处于中间地带的，它不需要标签，但是又从我们这里得到了一些反馈，因此我们把这一中间地带称为半监督学习
强化学习：
   强化学习不同于监督学习，因为数据没有标签，虽然从错误中学习这一总体思路是相同的，但是作用的机制不同
   相比之下，在监督学习中，由系统生成一个结果（通常是一个类别或一个预测值），然后我们将其与所提供的正确
   结果进行比较；而在强化学习中，是没有正确结果的，因为数据没有标签，而是通过反馈来告诉我们做得有多好
   特点：环境（道路反馈）会向智能体（自动驾驶的汽车）发送一个奖励信号，这个奖励信号是一个程度值
深度学习：
   基于一系列的离散的层（layer）构建机器学习算法。如果将这些层垂直堆叠，就说这个结果是有深度
  （depth）的，或者说算法是有深度的。
  泛化误差：如果预测大部分是正确的，那么我们就说它具有很高的准确率，或者说泛化误差（generalization error）很小。
贝叶斯
   似然：P(D∣θ)事件θ发生的情况下D发生的概率
   先验：P(θ) 是先验分布，表示在观测数据之前对参数θ的不确定性的概率分布（在抛硬币之前拿到不公平硬币的概率）。
   后验：P(θ∣D)表示在给定数据 D后参数 θ 的条件概率分布（抛一次硬币之后正面朝上，此时手中时公平或不公平硬币的概率分布）
   证据：P(D) 指事件D以任何方式发生的概率(可能挑选的每个硬币正面朝上的概率的和)
数据验证：
    1.想要知道一个系统在新的、未知的数据上能做得多好，首选的方法就是给它新的、未知的数据，
      我们称这些新的数据点或样本为测试数据（test data）或测试集
    2.训练或测试规则：1.我们决不从测试数据中学习，因为会破坏我们对系统总体能力进行评估的可靠性
    3.系统用测试数据进行学习，被称之为数据泄露（data leakage），也称为数据污染（data contamination）或处理受污染数据
    3.通常将原始输入数据拆分为训练集(用来训练系统，学习特征)，验证集（验证系统性能，选择效果最好的超参数，用作学习过程的一部分），测试集（验证系统性能）
一般流程：
      对于超参数的每一次变化，我们都会训练训练集，而后在验证集上评估系统的性能，之后会选择一组实现效
      果最好的超参数，并通过在从未见过的测试集上运行系统来评估系统的性能。
使用验证数据的结果作为系统的最终评估结果的问题：
      会导致数据泄露，因为尽管分类器没有直接地从验证数据中学习，但是验证数据影响了我们对分类器的选择。我们选择了一个在验证数据
      上表现最好的分类器，在正式应用前，我们对分类器在验证数据上的表现的了解将“泄露”到最终的评估情况中
交叉验证：（当数据量过少时）
      每次训练时将训练数据分割为临时训练集和临时验证集时，这些数据被分割为新的集，这样每次的数据都是全新的，未知的，
      所以用它来评估分类器的性能是公平的。
K折叠交叉验证：
      将训练数据拆分为1-5块，通过索引循环，每次拿1块当验证集，其余4块作为训练集，这样我们就可以将所有数据都拿来训练
过拟合：
      如果系统在训练数据中学习得很多且表现很好，但在面对新数据时表现得很糟糕，我们就可以说系统是过拟合的
过拟合的原因：
       我们“过多地学习了”或者说“过多地适应了”输入的数据。换句话说，我们从它们中学习得太多了，对一些细节权重过大，导致细节代替了普
      遍规则。
过拟合的解决办法：
       1.通过正则化的方法，我们可以鼓励系统尽可能长时间地学习普遍的规则，而不是去拼命地记住细节
       2.我们可以在捕捉到系统开始记忆这些细节的时候，停止它的学习过程。
欠拟合：
       描述了一种规则太过模糊或者普遍的情况，导致泛化误差过高
正则化方法：
       1.把各个特征的权重压缩至比较小的数值，使其不会出现某些特征权重过大而成为一般规则，λ（lambda）来表示正则
      化量，越大说明正则化程度越高
偏差：
       1.在一组数据中，各个数据表现简单相似，没有足够的灵活度，这样的一组数据就表现出了高偏差
方差：
        2.在一组数据中，各个数据表现复杂切不相同，则它们有着高方差。
感知机：
      有若干个输入值，每个输入值对应一个权重和，权重可自行变化，将输入值✖权重之和加上偏置值作为检测值，经过检测之后输出特定的值
激活函数：
      在感知机的输出处，用一个数学函数替代了整个检测再输出的步骤——它将和值（包括偏置）作为输入，然后返回一个新的值作为输出
      这个函数被称之为激活函数.

-----------------------------------scikit-learn--------------------------------------------------------------------
fit():
      每个估算器都会提供的。它需要两个强制参数，包含估算器将从中学习的样本以及与它们相关联的值（或目标）
predict()：
      评估函数，一旦训练了估算器，我们就可以要求它用predict()来评估新的样本。这至少需要一个参数，那就是新的样本，我们希望估算器为其赋
      值。例程会返回描述新数据的信息，通常这是一个NumPy数组，每个样本对应一个数字或一个类
decision_function()：
      同样是评估函数，与predict不同，decision_function将一组样本作为输入，并为每个类和每个输入返回“confidence”分数，其中较大的值表示更高的可信度
predict_proba()：
      输出概率，所有分类结果概率和为1，比decision_function()更加直观。
变换器（transform）：
      scikit-learn提供了各种各样的对象，称为变换器，它可以执行许多不同类型的数据变换。每个变换器接收一个包含样本数据的NumPy数组，并返回一个变换数组。
      

      
      
     